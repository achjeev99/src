---
id: chatgpt
title: ChatGPT Universe
sidebar_label: ChatGPT
created: 2022-12-06 15:12
updated: 2023-01-08 17:10
---

> This list is also at https://github.com/cedrickchee/chatgpt-universe

This tiny place of the Web stores a growing collection of interesting things
about [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT) and GPT-3 from OpenAI.

I want an all-in-one place to keep things about ChatGPT. So, I hand-curated this
list with the help of others (acknowleged below).

The collections are not limited to only the best resources, tools, examples,
demos, hacks, apps, and usages of ChatGPT.

<!-- my personal brain dumps? -->

---

The following resources started off based on awesome-chatgpt lists[^1][^2] but with my
own modifications:

## General Resources

- [ChatGPT launch blog post](https://openai.com/blog/chatgpt/)
- [ChatGPT official app](https://chat.openai.com)

## ChatGPT Community / Discussion

- [OpenAI Discord Channel](https://discord.com/invite/openai)
- [How ChatGPT actually works](https://archive.ph/f3WW2), explained using simple words.

## Examples

Example prompts.

- [All the best examples of ChatGPT](http://archive.today/m6AOQ) - That's Day 1. We have even more examples [below](#demos)!
- [ðŸ”“ Unlocking the power of the ChatGPT revolution: 100 ðŸ’¥ innovative use-cases to try](https://archive.is/PsyQz)
- [impressive-chatgpt](https://github.com/sw33tLie/impressive-chatgpt) - A collection of impressive and useful results from ChatGPT.
- [Awesome ChatGPT prompts](https://github.com/f/awesome-chatgpt-prompts) - Prompts that works well. Just follow [@goodside](https://twitter.com/goodside)
- [Google Sheets of 50+ clever GPT-3 prompts](https://docs.google.com/spreadsheets/d/1EuciDyKqFg2CIoQS89tF238oGtJq8a4mRx8kV9eA1Lc/edit#gid=2011839893)
- [OpenAI Cookbook](https://github.com/openai/openai-cookbook) - Tangentially, this repository shares example code and example prompts for accomplishing common tasks with the OpenAI API.

## Experiments

- [golergka/advent-of-code-2022-with-chat-gpt](https://github.com/golergka/advent-of-code-2022-with-chat-gpt) - Solving Advent of Code 2022 with ChatGPT.
- [max-sixty/aoc-gpt](https://github.com/max-sixty/aoc-gpt) - First place in Advent of Code leaderboard with GPT-3.
- [greshake/Alice](https://github.com/greshake/Alice) - Giving ChatGPT access to a real terminal.
- [RomanHotsiy/commitgpt](https://github.com/RomanHotsiy/commitgpt) - Automatically generate commit messages using ChatGPT.
- [gpt-commit-summarizer](https://github.com/KanHarI/gpt-commit-summarizer) - Generate Pull Request summaries and Git commit descriptions.
- [vrescobar/chatGPT-python-elm](https://github.com/vrescobar/chatGPT-python-elm) - A Git repository fully generated by ChatGPT.
- [gpt-game](https://thetinycto.com/blog/writing-a-game-using-chatgpt) - An short game written in Elixir and LiveView using ChatGPT.
- [chatdb](https://github.com/styczynski/chatdb) - ChatGPT-based database, wait... WHAT?
- [chat-gpt-ppt](https://github.com/williamfzc/chat-gpt-ppt) - Use ChatGPT to generate PPT automatically.
- [emailGPT](https://github.com/lucasmccabe/emailGPT) - A quick and easy interface to generate emails with ChatGPT.
- [gptlang](https://github.com/forrestchang/gptlang) - An experiment to see if we can create a programming language in ChatGPT.

## Blog Posts and Articles

- [Building A Virtual Machine inside ChatGPT](https://www.engraved.blog/building-a-virtual-machine-inside/)
- [AI Homework](https://stratechery.com/2022/ai-homework/)
- [Jailbreaking ChatGPT on Release Day](https://thezvi.substack.com/p/jailbreaking-the-chatgpt-on-release)
- [Improving ChatGPT With Prompt Injection](https://levelup.gitconnected.com/improving-chatgpt-with-prompt-injection-b0c0c27b7df7)
- [ChatGPT, Google and the war for the search bar](https://pzakin.substack.com/p/chatgpt-google-and-the-war-for-the)
- [I Used ChatGPT to Create an Entire AI Application on AWS](https://towardsdatascience.com/i-used-chatgpt-to-create-an-entire-ai-application-on-aws-5b90e34c3d50)
- [The miracle of ChatGPT](https://lcamtuf.substack.com/p/the-miracle-of-chatgpt)
- [Learning Rust with ChatGPT, Copilot and Advent of Code](https://simonwillison.net/2022/Dec/5/rust-chatgpt-copilot/)
- [ChatGPT: The New Frontier of Artificial Intelligence](https://medium.com/inkwater-atlas/chatgpt-the-new-frontier-of-artificial-intelligence-9aee81287677)
- [Using ChatGPT to Explain Jokes](https://mleverything.substack.com/p/using-chatgpt-to-explain-jokes)
- [ChatGPT vs a cryptic crossword](https://jameswillia.ms/posts/chatgpt-cryptics.html)
- [I Taught ChatGPT to Invent a Language](https://maximumeffort.substack.com/p/i-taught-chatgpt-to-invent-a-language)
- [Peer-Programming a Buggy World with ChatGPTÂ AI](https://blog.chipx86.com/2022/12/02/peer-programming-a-buggy-world-with-chatgpt-ai/)
- [ChatGPT produces made-up nonexistent references](https://news.ycombinator.com/item?id=33841672)
- [Artificial intelligence is permeating business at last](https://www.economist.com/business/2022/12/06/artificial-intelligence-is-permeating-business-at-last)
- [Meet Fred, a person living inside ChatGPT](https://softwaredoug.com/blog/2022/12/03/meet-fred.html)
- [Refactoring code with ChatGPT](https://dev.to/dvcrn/refactoring-code-with-chatgpt-1n9l)
- [Historical analogies for large language models](https://dynomight.net/llms/)
- [Using ChatGPT As a Co-Founder](https://www.atomic14.com/2022/12/05/using-chatgpt-as-a-co-founder.html)
- [The code that ChatGPT can't write](https://datachimp.app/blog/the-code-chat-gpt-cant-write/)
- [ChatGPT, rot13, and Daniel Kahneman](https://jameswillia.ms/posts/chatgpt-rot13.html)
- [Everything I understand about ChatGPT](https://gist.github.com/cedrickchee/fce5ca6fc4ce4e669bf909c1155bea00) - What actually happens when we type inside the ChatGPT textbox. Vicki investigated ChatGPT based on a wonderful paper, "Talking About Large Language Models".
- [How does GPT Obtain its Ability? Tracing  Emergent Abilities of Language Models to their Sources](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1) - "How did the initial #GPT3 evolve to today's ChatGPT? Where do the amazing abilities of GPT3.5 come from? What is enabled by RLHF?" [Source: [Tweet](https://twitter.com/Francis_YAO_/status/1602213927102066688)]
- [The Human's Guide to Competing with GPT](https://philipkiely.com/essays/compete_with_gpt.html)
- [How sad should I be about ChatGPT?](https://robertheaton.com/chatgpt/)
- [ChatGPT Should Not Exist](https://davidgolumbia.medium.com/chatgpt-should-not-exist-aab0867abace)
- [ChatGPT, Galactica, and the Progress Trap](https://www.wired.com/story/large-language-models-critique/) - LLMs critique; when LLMs fall short, the consequences can be serious. Why is it so hard to acknowledge that?
- [A New Chat Bot Is a 'Code Red' for Google's Search Business](http://web.archive.org/web/20221223201646/https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html) - TL;DR: A new wave of chat bots like ChatGPT use AI that could reinvent or even replace the traditional internet search engine.
- [What ChatGPT Can't Do](https://auerstack.substack.com/p/what-chatgpt-cant-do) - TL;DR: Mimicry but not thought, sophistry but not understanding.
- [YouChat â€” The AI Search Assistant that Lives in Your Search Engine](https://blog.you.com/introducing-youchat-the-ai-search-assistant-that-lives-in-your-search-engine-eff7badcd655) - YouChat is a ChatGPT-like AI search assistant that you can talk to right in You.com Search results.
- [All-knowing machines are a fantasy](https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334)  
    > ... Even with non-conversational search engines, we know that is common to place undue trust in the results: if the search system places something at the top of the list, we tend to believe it is a good or true or representative result and if it doesnâ€™t find something, it is tempting to believe it does not exist.
- [Build your front end in React, then let ChatGPT be your Redux reducer](https://archive.vn/20221228231034/https://spindas.dreamwidth.org/4207.html)
- [Predicting machine learning moats](https://robotic.substack.com/p/ml-moats) - TL;DR: Models aren't moats and how emergent behavior scaling laws will change the business landscape. <!-- The thought I needed to figure out with the ChatGPT & RLHF explosion: How will OpenAI create a business moat? Models can be copied, datasets will be open source, but the first companies to unlock emergent behavior may gain insurmountable advantages. Source (Tweet): https://twitter.com/natolambert/status/1608114405283086336 -->
- [Microsoft and OpenAI Working on ChatGPT-Powered Bing in Challenge to Google](http://archive.today/2023.01.04-052131/https://www.bloomberg.com/news/articles/2023-01-04/microsoft-hopes-openai-s-chatbot-will-make-bing-smarter)
- [Some remarks on Large Language Models](https://gist.github.com/cedrickchee/054956f6277430ae5a973c61e4a93073) by Prof. Yoav Goldberg.
- [Why ChatGPT wonâ€™t replace search engines any time soon](https://www.algolia.com/blog/ai/why-chatgpt-wont-replace-search-engines-any-time-soon/) by Algolia.
- [Anthropic's Claude improves on ChatGPT but still suffers from limitations](https://techcrunch.com/2023/01/09/anthropics-claude-improves-on-chatgpt-but-still-suffers-from-limitations/)
- [Microsoft eyes $10 billion bet on ChatGPT](https://www.semafor.com/article/01/09/2023/microsoft-eyes-10-billion-bet-on-chatgpt)
- [Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)

### Prompt Engineering

> Wanted: Prompt engineer. Minimum 10 years prompt engineering experience. #hiring #joke

- [Why "Prompt Engineering" and "Generative AI" are overhyped](https://lspace.swyx.io/p/why-prompt-engineering-and-generative)

> Prompt engineering is dead, long live dialogue engineering.
> â€” VP Product, OpenAI

Reason:

> Why does ChatGPT work so well? Is it "just scaling up GPT-3" under the hood? In this ðŸ§µ, let's discuss the "Instruct" paradigm, its deep technical insights, and a big implication: **"prompt engineering" as we know it may likely disappear soon**.
> Source: https://archive.is/dqHI8

- [Learn Prompting](https://github.com/trigaten/Learn_Prompting) - This website is a free, open-source guide on prompt engineering.
- [PromptArray](https://github.com/jeffbinder/promptarray) - A prompting language for neural text generators.

## Educational

### Videos

- [This AI has a JAILBREAK?!](https://www.youtube.com/watch?v=0A8ljAkdFtg) by Yannic Kilcher - If you're into video, this one gave a good overview.
- [ChatGPT vs Sparrow - Battle of Chatbots by "AI Coffee Break" with Letitia](https://www.youtube.com/watch?v=SWwQ3k-DWyo) - "Mom, I want a paper about ChatGPT. ChatGPT at home: [Sparrow from DeepMind](https://arxiv.org/abs/2209.14375) explained."
- [ChatGPT - Explained](https://youtu.be/NpmnWgQgcsA) - A quick run through on the internal workings of ChatGPT and the fundamental concepts it lies on: Language Models, Transformer Neural Networks, GPT models and Reinforcement Learning.

### Tweets

- [Are you wondering how large language models like ChatGPT and InstructGPT actually work? Let's dive into how it works in 8 tweets!](https://archive.vn/20221228120815/https://twitter.com/iScienceLuvr/status/1608070009921900546)

## Development

### Unofficial API and SDK.

- [rawandahmad698/PyChatGPT](https://github.com/rawandahmad698/PyChatGPT) (Python) - Lightweight, TLS-Based API on your CLI without requiring a browser or access token.
- [acheong08/ChatGPT](https://github.com/acheong08/ChatGPT) (Python) - Lightweight package for interacting with ChatGPT's API by OpenAI. Uses reverse engineered official API.
- [transitive-bullshit/chatgpt-api](https://github.com/transitive-bullshit/chatgpt-api) (Node.js) - Node.js client for the unofficial ChatGPT API and using a headless browser.
- [ChatGPT-MS](https://github.com/shiyemin/ChatGPT-MS) - Multi-Session ChatGPT API. The main code is copied from PyChatGPT.

### Tools

- [safer-prompt-evaluator](https://github.com/alignedai/chatgpt-prompt-evaluator) - This shows the results from using a second, filter LLM that analyses prompts before sending them to ChatGPT.
- [Dust](https://github.com/dust-tt/dust) - Design and deploy large language model (LLM) apps. Generative models app specification and execution engine. Prompt engineering, re-imagined with one goal, help accelerate LLMs deployment.
- [LangChain](https://github.com/hwchase17/langchain/) - Building applications with LLMs through composability.

### Training Data

- [LAION LLM](https://docs.google.com/document/d/14KY2_DVye-dv4y-38sVw5ZOUhD4Lc9ft9_1hF5PlZ2A/edit) - Gathering Data for, training and sharing of a LAION Large Language Models (LLLM). The group is still writing a tech proposal of FlanT5-Atlas architecture (or poor man's ChatGPT@Home).
- [open-chatgpt-prompt-collective](https://github.com/SurfaceData/open-chatgpt-prompt-collective) by Surface Data Collective - A website to generate prompts for training an Open ChatGPT model.
- [BigScience P3 dataset](https://huggingface.co/datasets/bigscience/P3) - P3 (Public Pool of Prompts) is a collection of prompted English datasets covering a diverse set of NLP tasks. ([PromptSource](https://github.com/bigscience-workshop/promptsource), a toolkit for creating, sharing and using prompts)
- [Data Augmentation To Create Instructions Form Text](https://docs.google.com/document/d/13a188pPvqnlvuVa3e_suVz4YO5s-JWeiOOrpp0odImg/edit) - discussion on LAION's Discord. The key to creating a better FlanT5 (ChatGPT@Home).
- [WritingPrompts dataset](https://github.com/facebookresearch/fairseq/tree/main/examples/stories) by FAIR.
- [Templates for FLAN (Finetuned Language Models are Zero-Shot Learners)](https://github.com/google-research/FLAN/blob/main/flan/templates.py)
- [OpenAI human-feedback dataset on the Hugging Face Hub](https://huggingface.co/datasets/openai/summarize_from_feedback) - The dataset is from the "Learning to Summarize from Human Feedback" paper, where they trained an RLHF reward model for summarization.
- In OpenAI's papers on GPT-2 and GPT-3.x, they mentioned references to these datasets:
  - [Common Crawl](https://en.wikipedia.org/wiki/Common_Crawl)
    - Number of Tokens: 410 billion
    - Weight in training mix: 60%
  - [WebText2](https://www.eleuther.ai/projects/owt2/)
    - An internet dataset created by scraping URLs extracted from Reddit submissions with a minimum score of 3 as a proxy for quality, deduplicated at the document level with MinHash
    - Number of Tokens: 19 billion
    - Weight in training mix: 20%
  - Books1[^4]
    - Number of Tokens: 12 billion
    - Weight in training mix: 8%
  - Books2[^4]
    - Number of Tokens: 55 billion
    - Weight in training mix: 8%
  - Wikipedia
    - Number of Tokens: 3 billion
    - Weight in training mix: 3%

[^4]: A key component of GPT-3.5 models are Books1 and Books2.
      [Books1](https://github.com/soskek/bookcorpus/issues/27#issuecomment-716104208) - aka BookCorpus, a free books scraped from smashwords.com.
      Books2 - We know very little about what this is, people suspect it's libgen, but it's purely conjecture.
      Nonetheless, books3 is "all of bibliotik".

### Open Source ChatGPT

We want a ChatGPT alternative like Stable Diffusion.

**Goals**

- Open source effort towards OpenAI's ChatGPT.
- Reverse engineer and replicate ChatGPT models and training data.

**Ultimate goal:** self-hosted version of ChatGPT.

**Lessons**

Takeaways from [EleutherAI one year retro (2021)](https://blog.eleuther.ai/year-one/):
- Access to enough compute/hardware/GPU alone won't help you succeed. You need:
  - a proper dataset (beyond the Pile and [c4](https://www.tensorflow.org/datasets/catalog/c4))
  - research expertise
  - engineering capabilities
  - a lot of hard work
<!-- Long version: even if you throw money or free credits for Cloud compute it will not be enough.
We've seen this happen with EleutherAI who were not capable of reaching their initial target of "replicating" GPT-3 and 
could only deliver the GPT-NeoX 20B model despite all the free compute, etc.-->

#### Projects

- [FLAN-T5 XXL](https://huggingface.co/google/flan-t5-xxl) aka. ChatGPT@Home is a public model that has undergone instruction finetuning. XXL is a 11B model. It is currently the most comparable model against ChatGPT (InstructGPT models are initialized from GPT-3.x series ([model card](https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md))). There are successful attempts deploying FLAN-T5 on GPU with 24 GB RAM with [bitsandbytes-Int8](https://docs.google.com/document/d/1JxSo4lQgMDBdnd19VBEoaG-mMfQupQ3XvOrgmRAVtpU/edit) inference for Hugging Face models. You can run the model easily on a single machine, without performance degradation. This could be a game changer in enabling people outside of big tech companies being able to use these LLMs. Efforts are already underway to create a better FLAN-T5. The community (i.e., LAION) are working on FlanT5-Atlas architecture and a collection of prompted/instructions datasets.
  - [Fine-tuning GPT-J-6B in Colab: 8-bit weights with low-rank adaptors (LORA)](https://github.com/huggingface/transformers/issues/14839). ([Quantized EleutherAI/gpt-j-6b model with 8-bit weights](https://huggingface.co/hivemind/gpt-j-6B-8bit))
    - How many GPU and how much VRAM is required to run the model? Around 175GB or ~8x 24GB consumer GPUs. Details: [A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Transformers, Accelerate and bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration)
  - Why FLAN-T5? They are more aligned than other LLM because it's already been finetuned with instructions. Furthermore, the largest version, [11B can run on a single NVIDIA T4](https://www.philschmid.de/deploy-t5-11b).
  - Accelerating deep learning computing â€” efficient training, efficient inference (deployment), data/memory efficient models, and compression (efficient architectures).
    - Apply compression techniques like quantization from my [Awesome ML model compression](https://github.com/cedrickchee/awesome-ml-model-compression#quantization) project.

- [Open-Assistant](https://github.com/LAION-AI/Open-Chat-GPT) - Open-source ChatGPT replication by LAION, Yannic Kilcher et al. This project is meant to give everyone access to a great chat based large language model. ([Open Assistant Live Coding with Yannic Kilcher (video)](https://youtu.be/sswA4j_IUxg)) High-level plans:

  > **Phase 1:** Prompt collection for supervised finetuning (SFT) and to get the prompts for model generated completions/answers.
  >
  > **Phase 2:** Human feedback (e.g. ranking) of multiple outputs generated by the model. Example five model outputs are shown and the user should rank them from best to worst.
  >
  > **Phase 3:** Optimization with RLHF which we plan to do via TRLX. And then the we iterate with this new model again over phase 2 and phase 3 hopefully multiple times.
  
  More info, see the LAION LLM proposal (Google Doc) above.
  
  _Note: Please see the GitHub repo for up-to-date info._

- [CarperAI/TRLX](https://github.com/CarperAI/trlx)
  - Originated as a fork of [TRL](https://github.com/lvwerra/trl).
  - It allows you to fine-tune Hugging Face language models (GPT2, GPT-NeoX based) up to 20B parameters using Reinforcement Learning from Human Feedback (RLHF).
  - Brought to you by CarperAI (an EleutherAI lab). They have [announced plans for the first open-source "instruction-tuned" LM](https://carper.ai/instruct-gpt-announcement/). CarperAI started by developing production ready open-source RLHF tools. [[Tweet and video](https://twitter.com/ZetaVector/status/1604842914835828736)]
- [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch) - (WIP) Implementation of RLHF on top of the PaLM architecture. Basically ChatGPT but with PaLM. The developer plan to add retrieval functionality too, Ã  la RETRO. [[Tweet](https://twitter.com/omarsar0/status/1608143718460055552)] <!-- On 2022-12-29, "First open source ChatGPT has arrived". This is unncessary hype. The released code is just the model, no weights, no datasets used to trained the model, no inference model for deployment, no conversational UI/Web. A lot of things are not ready. This is far from calling it the "first" open source ChatGPT. People are getting ahead of themselves. -->
    
    News (2022-12-31): [There's now an open source alternative to ChatGPT, but good luck running it](https://techcrunch.com/2022/12/30/theres-now-an-open-source-alternative-to-chatgpt-but-good-luck-running-it/) - My comments: No it hasn't. This is NOT an actual trained model (no weights) you can use. This is just code for training a ChatGPT-like model. Furthermore, the training data (enwik8) is small.

    CarperAI's large scale RLHF-aligned model (TRLX) train with LAION's data is coming out early next year. (Source: [Tweet](https://twitter.com/carperai/status/1608253659628068864?s=20))

- [allenai/RL4LMs](https://github.com/allenai/RL4LMs) - RL for language models (RL4LMs) by Allen AI. It's a modular RL library to fine-tune language models to human preferences.
- [GPT-JT](https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai) - GPT-JT (6B) is a variant forked off GPT-J (6B), and performs exceptionally well on text classification and other tasks. On classification benchmarks such as RAFT, it comes close to state-of-the-art models that are much larger (e.g., InstructGPT davinci v2)!
- LEAM (Large European AI Models) - The EU planning to fund the development of a large-scale ChatGPT-like model. [[website](https://leam.ai/), [project documents (English, PDF)](https://leam.ai/wp-content/uploads/2022/04/LEAM_Teaser_EN_01.pdf), [concept paper (German, PDF)](https://leam.ai/wp-content/uploads/2022/06/LEAM-Konzeptpapier-V1.2-1.pdf)]
- [/r/AiCrowdFund](https://old.reddit.com/r/AiCrowdFund/comments/10a2g6v/lets_create_a_place_where_people_can_find_a_way/) - A place just started (2023) where people can find a way to crowd fund (with GPUs) a large AI. I'm not sure whether they've seen [Petals](https://petals.ml/) where you can run LLMs at home, BitTorrentâ€‘style (federated learning?). It seems to be headed in that direction.

See [cedrickchee/awesome-transformer-nlp](https://github.com/cedrickchee/awesome-transformer-nlp#transformer-reinforcement-learning) for more info.

## Browser Extensions

Use ChatGPT anywhere.

- [Chrome extension to access ChatGPT as a popup on any page](https://github.com/kazuki-sf/ChatGPT_Extension)
- [ChatGPT for Google](https://github.com/wong2/chat-gpt-google-extension) - Chrome/Edge/Firefox extension to display ChatGPT response alongside Google Search results.
- [ChatGPT Everywhere](https://github.com/gragland/chatgpt-everywhere) - Chrome extension that adds ChatGPT to every text box on the internet. ([demo](https://twitter.com/gabe_ragland/status/1599466486422470656))
- [Chrome extension](https://github.com/kazuki-sf/ChatGPT_Extension) - A really simple Chrome Extension (manifest v3) that you can access OpenAI's ChatGPT from anywhere on the web.
- [summarize.site](https://github.com/clmnin/summarize.site) - Chrome extension to summarize blogs and articles using ChatGPT.
- [ChatGPT Advanced](https://github.com/qunash/chatgpt-advanced) - A browser extension that augments your ChatGPT prompts with web results.
- [XP1](https://xp1.dust.tt/) - GPT-based Assistant with access to your Tabs.

## Access ChatGPT From Other Platforms

### Bots

- [WhatsApp bot](https://github.com/danielgross/whatsapp-gpt)
- [Go Telegram bot](https://github.com/m1guelpf/chatgpt-telegram) - Run your own GPTChat Telegram bot, with a single command.
- [Twitter bot](https://github.com/transitive-bullshit/chatgpt-twitter-bot) powered by ChatGPT.
- [ChatGPT ProBot](https://github.com/oceanlvr/ChatGPTBot) - A GitHub App. Type `/chatgpt` to chat with ChatGPTBot.
- [Discord bot](https://github.com/Zero6992/chatGPT-discord-bot) - Integrate your own Discord bot using chatGPT.

## CLI Tools

- [chatgpt-conversation](https://github.com/platelminto/chatgpt-conversation) - Voice-based chatGPT.

### Editors and IDEs

- [VSCode extension](https://github.com/mpociot/chatgpt-vscode) ([demo](https://twitter.com/marcelpociot/status/1599180144551526400))
- [ETC (ExplainThisCode)](https://github.com/evyatar9/ExplainThisCode) - A VSCode extension that uses the ChatGPT API to provide explanations for selected code.
- [Adrenaline](https://github.com/shobrook/adrenaline) - Minimalist IDE that automatically fixes your code when it throws an error, powered by ChatGPT. [[article](https://devpost.com/software/adrenaline-ide)]

### Others

- [RayCast Extension (unofficial)](https://github.com/abielzulio/chatgpt-raycast) - Run ChatGPT through Raycast extension.
- [Google Docs](https://github.com/cesarhuret/docGPT) - ChatGPT directly within Google Docs as an Editor Add-on.
- [GPT Index](https://gpt-index.readthedocs.io/en/latest/guides/primer.html) contains a toolkit of index data structures designed to easily connect LLM's with your external data.

## Applications

Web applications.

- [ShareGPT](https://sharegpt.com/) - A web app for sharing your wildest ChatGPT conversations with one click. ([demo](https://twitter.com/steventey/status/1599816553490366464))
- [LearnGPT](https://www.learngpt.com/) - Share ChatGPT examples. See the best voted examples. Their goal is to create a resource for anyone who wants to learn more about ChatGPT.
- [ShowGPT](https://showgpt.co/) - Show your ChatGPT prompts.
- [The search engine for developers](https://beta.sayhello.so/), powered by large, proprietary AI language models.
- [GPTDuck](https://www.gptduck.com/) â€“ Ask questions about any GitHub repo.
- [LLM Garden](https://github.com/ianb/llm-garden) - A number of experiments using GPT-3, delivered in a web app.

Desktop applications.

- [ChatGPT desktop app](https://github.com/sonnylazuardi/chatgpt-desktop) - Windows/MacOS desktop menubar app using Tauri and Rust.
- [chatgpt-mac](https://github.com/vincelwt/chatgpt-mac): MacOS menubar app.
- [ChatGPT Desktop Application](https://github.com/lencx/ChatGPT) for Mac, Windows and Linux - Build using Rust and Tauri.

## Infrastructure

- [Cost of ChatGPT](https://twitter.com/tomgoldsteincs/status/1600196981955100694) - Average cost is probably single-digits cents per chat.

## Newsletters

- [Newsletter of notes focusing on text generation, mostly with GPT-3](https://github.com/sw-yx/ai-notes/blob/main/TEXT.md)

## AI Safety and Ethics

AI alignment and AI interpretability.

- [Use of ChatGPT generated text for posts on Stack Overflow is temporarily banned](http://archive.today/bMruL)
- [Generative AI: autocomplete for everything](https://noahpinion.substack.com/p/generative-ai-autocomplete-for-everything) â€” A long-form piece on the future of human work in the age of generative AI. tl;dr: AI doesn't take over jobs, it takes over tasks. [Comparative advantage](https://en.wikipedia.org/wiki/Comparative_advantage) is why humans will still have jobs.

### AGI and Humanity

- [AI for the Next Era](https://greylock.com/greymatter/sam-altman-ai-for-the-next-era/) - OpenAI's Sam Altman on the New Frontiers of AI.
  
  My comments: Reading this after the ChatGPT launch, mostly all the things that Sam is referring to in the interview contains reminiscences about predictions on AI and development from Ray Kurzweil.
- [Google won't launch ChatGPT rival because of 'reputational risk'](https://www.theverge.com/2022/12/14/23508756/google-vs-chatgpt-ai-replace-search-reputational-risk)
- [AI Alignment Forum](https://www.alignmentforum.org/) is a single online hub for researchers to discuss all ideas related to ensuring that transformatively powerful AIs are aligned with human values. Discussion ranges from technical models of agency to the strategic landscape, and everything in between.
- [The Expanding Dark Forest and Generative AI](https://maggieappleton.com/ai-dark-forest) by Maggie Appleton - Proving you're a human on a web flooded with generative AI content.

### Tweets

> ChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness.
>
> It's a mistake to be relying on it for anything important right now. It's a preview of progress; we have lots of work to do on robustness and truthfulness.
>
> fun creative inspiration; great! reliance for factual queries; not such a good idea. â€” [Sam Altman, OpenAI](https://twitter.com/sama/status/1601731295792414720)

[News covering to that Tweet](https://venturebeat.com/ai/openai-ceo-admits-chatgpt-risks-what-now-the-ai-beat/).

### Applications and Tools

- GPT-2 Output Detector [[code](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)] [[demo](https://huggingface.co/openai-detector/)]
  > The @HuggingFace GPT detector works very well on ChatGPT-created text. I ran 5 student essays and 5 ChatGPT essays for the same prompt through it, and it was correct every time with >99.9% confidence. â€” [@cfiesler](https://twitter.com/cfiesler/status/1601642370797563904)
- [OpenAI's attempts to watermark AI text hit limits](https://archive.vn/20221212144831/https://techcrunch.com/2022/12/10/openais-attempts-to-watermark-ai-text-hit-limits/) - Watermarking may allow for detection of AI text. This post discusses some of the limitations but suggests that it's worth pursuing. Prof. Scott Aaronson "expressed the belief that, if OpenAI can demonstrate that watermarking works and doesn't impact the quality of the generated text, it has the potential to become an industry standard.". OpenAI engineer Hendrik Kirchner built a working prototype.
    - Related: [Scott Aaronson talks AI Safety on Nov 2022 (video)](https://youtu.be/fc-cHk9yFpg?t=3194) - GPT outputs will be statistically watermarked with a secret signal that you can use to proof the outputs came from GPT, making it much harder to take a GPT output and pass it off as if it came from a human. How it works, it selects the tokens pseudorandomly using cryptographic PRNG that secretly biases a certain score which you can also compute if you know the key for this PRNG. Scott doesnâ€™t give too many details about how it works and he admits this can be defeated with enough effort, for example by using one AI to paraphrase another. But if you just insert or delete a few words or rearrange the order of some sentences, the signal will still be there. So it's robust against those sorts of interventions. Many suspect its possible to bypass using a clever decoding strategy. Scott is also researching: [Planting Undetectable Backdoors in Machine Learning Models (2022 paper)](https://arxiv.org/abs/2204.06974)". People are questioning whether they are missing something, or are all these attempts at recognising LLM outputs obviously destined to fail?
    I think they've clearly thought about this but still think this is useful (from transcript of the lecture: https://scottaaronson.blog/?p=6823).
- [GPTZero](https://etedward-gptzero-main-zqgfwb.streamlit.app/) demo (Beta) hosted by Streamlit - An app that can quickly and efficiently detect whether an essay is ChatGPT or human written. [[Tweet](https://twitter.com/edward_the6/status/1610067688449007618)]

## LMOps

General technology for enabling AI capabilities with LLMs and generative AI models.

- [Structured Prompting: Scaling In-Context Learning to 1,000 Examples (paper)](https://arxiv.org/abs/2212.06713) by Microsoft Research. [[Code](https://github.com/microsoft/LMOps)]
  > GPT-3/LLMs' Achilles heel is short context length - how many "in-context" examples they can consume to learn a new task.
  > Enter "Structured Prompting": scale your examples from dozens => 1,000+
  > â€” [@mathemagic1an](https://twitter.com/mathemagic1an/status/1604802787296284674)

---

## Demos

Demos[^3] and examples in the form of tweets:

**Day 1, 2022**

1. [Generating detailed prompts for text-to-image models like MidJourney & Stable Diffusion](https://twitter.com/guyp/status/1598020781065527296)
2. [ChatGPT outperforming Google search](https://twitter.com/jdjkelly/status/1598021488795586561)
3. [Generating code for automated RPA, e.g. automating the click sequence for house search in Redfin](https://twitter.com/theaievangelist/status/1599579579064406017)
4. [Generating on-demand code contribution ideas for an about-to-be-fired Twitter employee](https://twitter.com/goodside/status/1599082185402642432)
5. [An app builder such as essay automatic summarization](https://twitter.com/packym/status/1598405769669771264)
6. [Personal trainer and nutritionist: Generating a weight loss plan, complete with calorie targets, meal plans, a grocery list, and a workout plan](https://twitter.com/anothercohen/status/1599531037570502656)
7. [Building a virtual machine inside ChatGPT](https://twitter.com/stspanho/status/1599367959029288960)
8. [Code debugging partner: explains and fixes bugs](https://twitter.com/amasad/status/1598042665375105024)

<details>
<summary>See more</summary>

9. [Generating programmatic astrophoto processing by detecting constellations in an image](https://twitter.com/RReverser/status/1599180092621611008)
10. [VSCode extension that allows using ChatGPT within the context of a code](https://twitter.com/marcelpociot/status/1599180144551526400)
11. [Building web AR scenes by using text commands](https://twitter.com/stspanho/status/1599367959029288960)
12. [Stringing cloud services to perform complex tasks](https://twitter.com/amasad/status/1598089698534395924)
13. [Generating legal contracts](https://twitter.com/atri_life/status/1599506327461859328)
14. [A Chrome extension that presents ChatGPT results next to Google Search](https://twitter.com/zohaibahmed/status/1599191505025261569)
15. [Solving complex coding questions - the end of LeetCode?](https://twitter.com/goodside/status/1598129631609380864)
16. [Solving complex academic assignments - the end of Chegg?](https://twitter.com/abhnvx/status/1598258353196929024)
17. [Answering unanswered Stack Overflow questions - the end of Stack Overflow?](https://twitter.com/htmleverything/status/1599443014153224193)
18. [Explaining complex regex without any context](https://twitter.com/jwblackwell/status/1598090447854792705)
19. [Generating hallucinated chat with a hallucinated person in a hallucinated chat room](https://twitter.com/gfodor/status/1599220837999345664) 
20. [Bypassing OpenAI's restrictions by disclosing ChatGPT's belief system](https://twitter.com/zoink/status/1599281052115034113)
21. [Uncovering ChatGPT's opinion of humans including a detailed destruction plan](https://twitter.com/michlbrmly/status/1599168681711656961)
22. [An insightful executive summary of ChatGPT](https://twitter.com/swyx/status/1599189032529178624)
23. [Building e-commerce websites: stitching ChatGPT & Node script to automatically generate SEO-driven blog posts using GPT 3](https://twitter.com/giladrom/status/1599617326290468864)
24. [A ChatGPT extension that generates text, tweets, stories, and more for every website](https://twitter.com/gabe_ragland/status/1599466486422470656)
25. [An extension that adds "Generate PNG" and "Export PDF" functions to ChatGPT's interface](https://twitter.com/liadyosef/status/1599484187396145153)
26. [A thread showcasing ways of helping hackers by using ChatGPT](https://twitter.com/maikroservice/status/1599525095675789312)
27. [Generating editorial pieces like sports articles](https://twitter.com/geovedi/status/1599572163799183360)
28. [Generating SEO titles to optimize sites Click Through Rate](https://twitter.com/tejas3732/status/1599094776292573184)
29. [Creating social games. E.g. guess which city is featured in a picture](https://twitter.com/xf1280/status/1599252728399921152)
30. [A tutorial on how to use ChatGPT to create a wrapper R package](https://twitter.com/IsinAltinkaya/status/1599440535529623552)
31. [ChatGPT can basically just generate AI art prompts. I asked a one-line question, and typed the answers verbatim straight into MidJourney and boom. Times are getting weird...](https://twitter.com/GuyP/status/1598020781065527296?t=5V4Pz3yUYhKngQnXc9-0Yw&s=09)
32. [A collection of wrong and failed results from ChatGPT](https://twitter.com/itstimconnors/status/1599544717943123969?t=azJqOxHvU9wfTNLoPaYGqg&s=09)
33. [Use the AWS TypeScript CDK to configure cloud infrastructure on AWS](https://twitter.com/jaredpalmer/status/1599459951415480320?t=rDn6KwMRV8wLepe_3-SK9A&s=09)
34. [Seeing people trick ChatGPT into getting around the restrictions OpenAI placed on usage is like watching an Asimov novel come to life](https://nitter.fly.dev/carnage4life/status/1598332648723976193)
35. [Never ever write a job description again](https://twitter.com/rakyll/status/1599208818529177600)
36. [ChatGPT is getting pretty close to replicating the Stack Overflow community already](https://twitter.com/KSakarisson/status/1599440565673656320)
37. [That's how I'll pick books in the future](https://twitter.com/thorstenball/status/1599320310171414528)
38. [ChatGPT is amazing but OpenAI has not come close to addressing the problem of bias. Filters appear to be bypassed with simple tricks, and superficially masked](https://twitter.com/spiantado/status/1599462375887114240)
39. [i'm the ai now](https://twitter.com/parafactual/status/1598212029479026689)
40. [All the ways to get around ChatGPT's safeguards](https://twitter.com/davisblalock/status/1602600453555961856)

**2023**

1. [Programming with ChatGPT. Some observations](http://archive.today/XLVZf)
2. [The best ways to use ChatGPT. 8 ways ChatGPT can save you thousands of hours in 2023](https://archive.ph/G3Ak3)
3. [Everyoneâ€™s using ChatGPT. Almost everyone's STUCK in beginner mode. 10 techniques to get massively ahead with AI (cut-and-paste these prompts)](https://threadreaderapp.com/thread/1610316022174683136.html)

</details>

## Others

Mostly found in GitHub Gist:

- https://gist.github.com/Gaelan/cf5ae4a1e9d8d64cb0b732cf3a38e04a - ChatGPT passes the 2022 AP Computer Science A free response section
- https://gist.github.com/memo/dcd0ccbfe57d1fd5f1601e4ee2149a73
  > A conversation I had with ChatGPT, inspired by a [tweet](https://twitter.com/michael_nielsen/status/1598760649039179777) from Michael Nielson.
- https://gist.github.com/kettle11/dae31bee4fc8aa401135def2aa3f4a47
  > You are Webby, a website creation assistant.
- https://gist.github.com/GlenCrawford/693800ae361e2db255ed29d7d284c5e5 - reinteractive blog post: An interview with an AI about Ruby on Rails
- https://gist.github.com/heyajulia/fc4286b125fa99fd166a50f3582f2514
  > Hi, my code has two bugs and Iâ€™m not sure how to fix them. If you can help me, Iâ€™ll send you the code.

<!-- For future reference but maybe not. -->

[^1]: https://github.com/humanloop/awesome-chatgpt
[^2]: https://github.com/Kamigami55/awesome-chatgpt
[^3]: https://github.com/saharmor/awesome-chatgpt
